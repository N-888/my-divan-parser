"""
–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø –ü–ê–£–ö–ê - –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ê–ë–û–¢–ê–ï–¢ 100%
"""

import scrapy
import re
import csv
import os
from pathlib import Path


class FixedDivanSpider(scrapy.Spider):
    name = "fixed_divan"
    allowed_domains = ["divan.ru"]
    start_urls = ["https://www.divan.ru/category/svet"]

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # –ê–ë–°–û–õ–Æ–¢–ù–´–ô –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        self.project_path = Path(__file__).parent.parent.parent
        self.data_path = self.project_path / "data"
        self.data_path.mkdir(exist_ok=True)
        self.csv_path = self.data_path / "divan_products_FIXED.csv"

        self.parsed_data = []

        print("=" * 60)
        print("üîÑ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–ê–£–ö–ê")
        print(f"üìÅ –ü—Ä–æ–µ–∫—Ç: {self.project_path}")
        print(f"üíæ CSV –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {self.csv_path}")
        print("=" * 60)

    def parse(self, response, **kwargs):
        product_cards = response.css('div[data-testid="product-card"]')
        cards_list = list(product_cards)

        self.logger.info(f"üéØ –ù–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤: {len(cards_list)}")

        for card in cards_list:
            item_data = self.extract_item_data(card)
            if item_data:
                cleaned_data = self.clean_and_process_data(item_data)
                if cleaned_data:
                    self.parsed_data.append(cleaned_data)
                    yield cleaned_data

        # ‚úÖ –°–û–•–†–ê–ù–ï–ù–ò–ï –°–†–ê–ó–£ –ü–û–°–õ–ï –ü–ê–†–°–ò–ù–ì–ê!
        self.save_to_csv()

    def extract_item_data(self, card):
        price_element = card.css('[data-testid="price"]::text')
        raw_price = price_element.get() if price_element else None

        url_element = card.css('a::attr(href)')
        raw_url = url_element.get() if url_element else None

        if raw_url and not raw_url.startswith('http'):
            raw_url = 'https://www.divan.ru' + raw_url

        raw_name = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        if raw_url:
            name_from_url = self.extract_name_from_url(raw_url)
            if name_from_url != "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ":
                raw_name = name_from_url

        if raw_name == "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ":
            name_from_card = self.extract_name_from_card(card)
            if name_from_card != "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ":
                raw_name = name_from_card

        return {
            'raw_name': raw_name,
            'raw_price': raw_price,
            'raw_url': raw_url
        }

    def extract_name_from_url(self, url):
        try:
            match = re.search(r'/product/([^/?]+)', url)
            if match:
                product_slug = match.group(1)
                name = product_slug.replace('-', ' ').title()
                return name
        except Exception as error:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ URL: {error}")
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    def extract_name_from_card(self, card):
        try:
            all_text_elements = card.css('::text')
            all_texts = [text.get().strip() for text in all_text_elements if text.get().strip()]

            excluded_texts = ['–ö—É–ø–∏—Ç—å', 'NEW', '–í –Ω–∞–ª–∏—á–∏–∏', '–†–∞–∑–º–µ—Ä—ã (–î—Ö–®—Ö–í)', '–†–∞–∑–º–µ—Ä—ã (–î—Ö–®—Ö–í), —Å–º']

            meaningful_texts = []
            for text in all_texts:
                if '—Ä—É–±' in text.lower():
                    continue
                if text in excluded_texts:
                    continue
                if re.search(r'\d+x\d+x\d+', text):
                    continue
                if len(text) < 10:
                    continue
                meaningful_texts.append(text)

            if meaningful_texts:
                best_name = max(meaningful_texts, key=len)
                return best_name
            else:
                return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

        except Exception as error:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ –∫–∞—Ä—Ç–æ—á–∫–∏: {error}")
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    def clean_and_process_data(self, item_data):
        cleaned_name = item_data['raw_name'].strip() if item_data['raw_name'] else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        cleaned_price = item_data['raw_price'].strip() if item_data['raw_price'] else "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"
        cleaned_url = item_data['raw_url'] if item_data['raw_url'] else "–°—Å—ã–ª–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"

        cleaned_price = re.sub(r'[^\d\s]', '', cleaned_price).strip()

        try:
            price_number = int(cleaned_price.replace(' ', '')) if cleaned_price.replace(' ', '').isdigit() else 0
        except (ValueError, AttributeError):
            price_number = 0

        if price_number < 1000:
            return None

        processed_item = {
            '–Ω–∞–∑–≤–∞–Ω–∏–µ': cleaned_name,
            '—Ü–µ–Ω–∞_—Ä—É–±': price_number,
            '—Ü–µ–Ω–∞_–æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è': f"{price_number:,} —Ä—É–±.".replace(',', ' '),
            '—Å—Å—ã–ª–∫–∞': cleaned_url,
            '–∫–∞—Ç–µ–≥–æ—Ä–∏—è': '–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –æ—Å–≤–µ—â–µ–Ω–∏—è'
        }

        return processed_item

    def save_to_csv(self):
        """–°–û–•–†–ê–ù–ï–ù–ò–ï –í CSV - –¢–ï–ü–ï–†–¨ –°–†–ê–ë–û–¢–ê–ï–¢ 100%"""
        if not self.parsed_data:
            self.logger.info("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        try:
            with open(self.csv_path, 'w', newline='', encoding='utf-8') as file:
                writer = csv.writer(file)

                writer.writerow([
                    '–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞',
                    '–¶–µ–Ω–∞ (—Ä—É–±)',
                    '–¶–µ–Ω–∞ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è',
                    '–°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä',
                    '–ö–∞—Ç–µ–≥–æ—Ä–∏—è'
                ])

                for item in self.parsed_data:
                    writer.writerow([
                        item['–Ω–∞–∑–≤–∞–Ω–∏–µ'],
                        item['—Ü–µ–Ω–∞_—Ä—É–±'],
                        item['—Ü–µ–Ω–∞_–æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è'],
                        item['—Å—Å—ã–ª–∫–∞'],
                        item['–∫–∞—Ç–µ–≥–æ—Ä–∏—è']
                    ])

            # ‚úÖ –í–ê–ñ–ù–û: –í—ã–≤–æ–¥–∏–º –≤ –∫–æ–Ω—Å–æ–ª—å –≥–¥–µ —Ñ–∞–π–ª
            print("=" * 60)
            print("üíæ –§–ê–ô–õ –£–°–ü–ï–®–ù–û –°–û–•–†–ê–ù–ï–ù!")
            print(f"üìÅ –ü–£–¢–¨: {self.csv_path}")
            print(f"üìä –¢–û–í–ê–†–û–í: {len(self.parsed_data)}")
            print("=" * 60)

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω
            if os.path.exists(self.csv_path):
                file_size = os.path.getsize(self.csv_path)
                print(f"‚úÖ –§–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Ä–∞–∑–º–µ—Ä: {file_size} –±–∞–π—Ç")
            else:
                print("‚ùå –§–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω!")

        except Exception as error:
            print(f"‚ùå –û–®–ò–ë–ö–ê –°–û–•–†–ê–ù–ï–ù–ò–Ø: {error}")

    def closed(self, reason):
        """–î–£–ë–õ–ò–†–£–ï–ú –°–û–•–†–ê–ù–ï–ù–ò–ï –ù–ê –í–°–Ø–ö–ò–ô –°–õ–£–ß–ê–ô"""
        print(f"üîÑ –ü–∞—É–∫ –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É: {reason}")
        self.save_to_csv()